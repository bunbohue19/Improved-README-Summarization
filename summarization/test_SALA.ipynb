{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./drive/MyDrive/Improved-README-Summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from markdown import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set access tokens\n",
    "!huggingface-cli login --token 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\n",
    "\n",
    "# Specify cache directory\n",
    "%env TRANSFORMERS_CACHE=../../hf-pretrained-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Return item and drop from frame. Raise KeyError if not found.\n",
    "\"\"\"\n",
    "def pop(df : pd.DataFrame, idx : int):\n",
    "    readme = df['readme'][idx]\n",
    "    description = df['description'][idx]\n",
    "    result = {'readme' : readme, 'description' : description}\n",
    "    df.at[idx, 'readme'] = np.nan\n",
    "    df.at[idx, 'description'] = np.nan\n",
    "    return result\n",
    "\n",
    "# Few-shots prompting\n",
    "def generate_testing_prompt(readme, shots):\n",
    "    if len(shots) == 0:\n",
    "        return f\"\"\"### Instruction: Summarize the following README contents with LESS THAN 30 words. Your answer should be based on the provided README contents only.\n",
    "\n",
    "        ### README contents:\n",
    "        {readme.strip()}\n",
    "\n",
    "        ### Summary:\n",
    "        \"\"\".strip()\n",
    "    else:\n",
    "        prompt = \"\"\"### Instruction: Summarize the following README contents with LESS THAN 30 words. Your answer should be based on the provided README contents only.\n",
    "        ### For examples:\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(len(shots)):\n",
    "            prompt += f\"\"\"\n",
    "            ### README contents:\n",
    "            {shots[i]['readme'].strip()}\n",
    "\n",
    "            ### Summary:\n",
    "            {shots[i]['description'].strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        prompt += f\"\"\"\n",
    "        ### README contents:\n",
    "        {readme.strip()}\n",
    "\n",
    "        ### Summary:\n",
    "        \"\"\".strip()\n",
    "        return prompt\n",
    "\n",
    "# Function to remove tags\n",
    "def format_entry(md_data) :\n",
    "    html = markdown(md_data)\n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for a in soup.findAll('a', href=True):\n",
    "        a.decompose()\n",
    "    for data in soup(['style', 'script', 'img', 'pre', 'code']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"#+\", \" \", text)\n",
    "    return re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "\n",
    "def process_description(s: str) -> str:\n",
    "    if s.endswith('.'):\n",
    "        s = s[:-1]\n",
    "        s = re.sub(r\"\\. \", \", \", s)\n",
    "    return s + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_shots = 0\n",
    "num_of_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-hf\"\n",
    "OUTPUT_DIR = \"./zero-shot-prompting-codellama-2-7b_readsum\"\n",
    "test_csv_file = '../dataset/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "test_df = pd.read_csv(test_csv_file, usecols=['readme', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, readme in enumerate(test_df['readme']):\n",
    "    test_df.at[i, 'readme'] = format_entry(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = []\n",
    "if num_of_shots == 0:\n",
    "    pass\n",
    "elif num_of_shots == 1:\n",
    "    shots.append(pop(test_df, 8))\n",
    "elif num_of_shots == 2:\n",
    "    shots.append(pop(test_df, 8))\n",
    "    shots.append(pop(test_df, 10))\n",
    "elif num_of_shots == 3:\n",
    "    shots.append(pop(test_df, 8))\n",
    "    shots.append(pop(test_df, 10))\n",
    "    shots.append(pop(test_df, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    truncation=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_safetensors=True,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for readme, description in zip(test_df['readme'], test_df['description']):\n",
    "    readme = clean_text(str(readme))\n",
    "    description = process_description(str(description))\n",
    "\n",
    "    sample = {\n",
    "        \"readme\": readme,\n",
    "        \"description\": description,\n",
    "        \"prompt\": generate_testing_prompt(readme, shots),\n",
    "    }\n",
    "    samples.append(sample)\n",
    "results_df = pd.DataFrame(samples)\n",
    "\n",
    "# Load metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "print(\"Testing...\")\n",
    "\n",
    "### Get the score per sample\n",
    "idx = 1\n",
    "results, predictions = [], []\n",
    "for prompt, description in zip(results_df['prompt'], results_df['description']):\n",
    "    inputs = tokenizer(prompt, max_length=4096, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=100, temperature=0.0001)\n",
    "\n",
    "    prediction = tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
    "    reference = description\n",
    "\n",
    "    result = rouge.compute(predictions=[prediction], references=[reference])\n",
    "    result['rouge1'] = round(result['rouge1'] * 100, 2)\n",
    "    result['rouge2'] = round(result['rouge2'] * 100, 2)\n",
    "    result['rougeL'] = round(result['rougeL'] * 100, 2)\n",
    "    result['rougeLsum'] = round(result['rougeLsum'] * 100, 2)\n",
    "\n",
    "    print('Sample: ', idx)\n",
    "    print('ROUGE-1 : ', result['rouge1'],\n",
    "          '\\nROUGE-2 : ', result['rouge2'],\n",
    "          '\\nROUGE-L : ', result['rougeL'],\n",
    "          '\\nROUGE-LSUM : ', result['rougeLsum'])\n",
    "    print('\\n')\n",
    "    idx += 1\n",
    "    results.append(result)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "r1s, r2s, rls, rlsums = [], [], [], []\n",
    "for result in results:\n",
    "    r1s.append(result['rouge1'])\n",
    "    r2s.append(result['rouge2'])\n",
    "    rls.append(result['rougeL'])\n",
    "    rlsums.append(result['rougeLsum'])\n",
    "\n",
    "r1_df = pd.DataFrame(data=r1s, columns=['ROUGE-1'])\n",
    "r2_df = pd.DataFrame(data=r2s, columns=['ROUGE-2'])\n",
    "rl_df = pd.DataFrame(data=rls, columns=['ROUGE-L'])\n",
    "rlsum_df = pd.DataFrame(data=rlsums, columns=['ROUGE-LSUM'])\n",
    "\n",
    "predictions_df = pd.DataFrame(data=predictions, columns=['prediction'])\n",
    "\n",
    "for r1 in r1_df:\n",
    "    r1_df.loc[-1] = [r1]\n",
    "    r1_df.index += 1\n",
    "r1_df.index -= 1\n",
    "\n",
    "for r2 in r2_df:\n",
    "    r2_df.loc[-1] = [r1]\n",
    "    r2_df.index += 1\n",
    "r2_df.index -= 1\n",
    "\n",
    "for rl in rl_df:\n",
    "    rl_df.loc[-1] = [r1]\n",
    "    rl_df.index += 1\n",
    "rl_df.index -= 1\n",
    "\n",
    "for rlsum in rlsum_df:\n",
    "    rlsum_df.loc[-1] = [r1]\n",
    "    rlsum_df.index += 1\n",
    "rlsum_df.index -= 1\n",
    "\n",
    "for prediction in predictions_df:\n",
    "    predictions_df.loc[-1] = [prediction]\n",
    "    predictions_df.index += 1\n",
    "predictions_df.index -= 1\n",
    "\n",
    "full_results_df = pd.concat([results_df, predictions_df, r1_df, r2_df, rl_df, rlsum_df], axis=1)\n",
    "full_results_df = full_results_df.dropna()\n",
    "full_results_df.to_csv(f'./drive/MyDrive/Improved-README-Summarization/results/result-{num_of_shots}-shots_llama2-7b_readme_summarization.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
