{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/4TData/vuquang/anaconda3/envs/readsum/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from markdown import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /mnt/4TData/vuquang/.cache/huggingface/token\n",
      "Login successful\n",
      "env: WANDB_API_KEY=1183ae2e25d9d913eb2e8c1dc43b7cdba6c18910\n"
     ]
    }
   ],
   "source": [
    "# Set access tokens\n",
    "!huggingface-cli login --token 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\n",
    "%env WANDB_API_KEY=1183ae2e25d9d913eb2e8c1dc43b7cdba6c18910\n",
    "# %env TRANSFORMERS_CACHE=./drive/MyDrive/Improved-README-Summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# You need to change this parameter according to your real path.\n",
    "OUTPUT_DIR = \"./zero-shot-prompting-llama-2-7b_readsum_29-6-2024\"\n",
    "train_csv_file = '../dataset/train.csv'\n",
    "val_csv_file = '../dataset/validation.csv'\n",
    "test_csv_file = '../dataset/updated_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_safetensors=True,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_prompt(readme, summary, shots):\n",
    "    if len(shots) == 0:\n",
    "        return f\"\"\"### Instruction: You are a helpful assistant. You need to summarize the following README contents. A good answer should be based on the provided README contents only and LESS THAN 20 words.\n",
    "\n",
    "        ### README contents:\n",
    "        {readme.strip()}\n",
    "\n",
    "        ### Summary:\n",
    "        {summary}\n",
    "        \"\"\".strip()\n",
    "    else:\n",
    "        prompt = \"\"\"### Instruction: You are a helpful assistant. You need to summarize the following README contents. A good answer should be based on the provided README contents only and LESS THAN 20 words.\n",
    "        ### For examples:\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(len(shots)):\n",
    "            prompt += f\"\"\"\n",
    "            ### README contents:\n",
    "            {shots[i]['readme'].strip()}\n",
    "\n",
    "            ### Summary:\n",
    "            {shots[i]['description'].strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        prompt += f\"\"\"\n",
    "        ### README contents:\n",
    "        {readme.strip()}\n",
    "\n",
    "        ### Summary:\n",
    "        {summary}\n",
    "        \"\"\".strip()\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv(train_csv_file, usecols=['readme', 'description'])\n",
    "val_df = pd.read_csv(val_csv_file, usecols=['readme', 'description'])\n",
    "test_df = pd.read_csv(test_csv_file, usecols=['readme', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Return item and drop from frame. Raise KeyError if not found.\n",
    "\"\"\"\n",
    "def pop(df : pd.DataFrame, idx : int):\n",
    "    readme = df['readme'][idx]\n",
    "    description = df['description'][idx]\n",
    "    result = {'readme' : readme, 'description' : description}\n",
    "    df.at[idx, 'readme'] = np.nan\n",
    "    df.at[idx, 'description'] = np.nan\n",
    "    return result\n",
    "\n",
    "# Function to remove tags\n",
    "def format_entry(md_data) :\n",
    "    html = markdown(md_data)\n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for a in soup.findAll('a', href=True):\n",
    "        a.decompose()\n",
    "    for data in soup(['style', 'script', 'img', 'pre', 'code']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def process_description(s: str) -> str:\n",
    "    if s.endswith('.'):\n",
    "        s = s[:-1]\n",
    "        s = re.sub(r\"\\. \", \", \", s)\n",
    "    return s + '.'\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"#+\", \" \", text)\n",
    "    return re.sub(r\"\\^[^ ]+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, readme in enumerate(train_df['readme']):\n",
    "    train_df.at[i, 'readme'] = format_entry(readme)\n",
    "\n",
    "for i, readme in enumerate(val_df['readme']):\n",
    "    val_df.at[i, 'readme'] = format_entry(readme)\n",
    "\n",
    "for i, readme in enumerate(test_df['readme']):\n",
    "    test_df.at[i, 'readme'] = format_entry(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_shots = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = []\n",
    "\n",
    "if num_of_shots == 0:\n",
    "    pass\n",
    "elif num_of_shots == 1:\n",
    "    shots.append(pop(test_df, 8))\n",
    "elif num_of_shots == 2:\n",
    "    shots.append(pop(test_df, 8))\n",
    "    shots.append(pop(test_df, 10))\n",
    "elif num_of_shots == 3:\n",
    "    shots.append(pop(test_df, 8))\n",
    "    shots.append(pop(test_df, 10))\n",
    "    shots.append(pop(test_df, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_with_prompt(entry):\n",
    "    readme = entry['readme']\n",
    "    readme = clean_text(readme)\n",
    "    description = process_description(entry['description'])\n",
    "    return {\n",
    "        \"formatted_readme\": readme,\n",
    "        \"summary\": description,\n",
    "        \"prompt_text\": generate_training_prompt(readme, description, shots),\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return data.shuffle(seed=42).map(generate_sample_with_prompt).remove_columns(\n",
    "        [\n",
    "            \"readme\",\n",
    "            \"description\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5831 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5831/5831 [00:01<00:00, 4177.53 examples/s]\n",
      "Map: 100%|██████████| 834/834 [00:00<00:00, 5029.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_dataset = process_dataset(train_dataset)\n",
    "processed_val_dataset = process_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction: You are a helpful assistant. You need to summarize the following README contents. A good answer should be based on the provided README contents only and LESS THAN 20 words.\\n\\n        ### README contents:\\n        Table of contentsIntroductionOverview is a command-line tool (CLI) for making updates across multiple GitHub repositories with a single command. You give :and will:Git-xargs leverages goroutines to perform the repo-updating work in parallel, so it is very fast.For example, have you ever needed to add a particular file across many repos at once? Or to run a search and replace to change your company or product name across 150 repos with one command? What about upgrading Terraform modules to all use the latest syntax? How about adding a CI/CD configuration file, if it doesn\\'t already exist, or modifying it in place if it does, but only on a subset of repositories you select?You can handle these use cases and many more with a single command.Example: writing a new file to every repo in your GitHub organizationAs an example, let\\'s use to create a new file in every repo:git-xargs \\\\ --branch-name test-branch \\\\ --github-org \\\\ --commit-message \"Create hello-world.txt\" \\\\ touch hello-world.txt Here\\'s what it looks like in action:In this example, every repo in your org will have a new file named hello-world.txt written to it with the contents \"Hello, World!\". You\\'ll then receive an easy-to-read printout of exactly what happened on : * * * * * * * * * ** GIT-XARGS RUN SUMMARY @ 2021-04-12 23:05:18.478435534 +0000 UTC Runtime in seconds: 4 COMMAND SUPPLIED [touch hello-world.txt] REPOS SUPPLIED VIA --repos FILE FLAG │────────────────────────│────────────────────────│ │ ORGANIZATION NAME (5) │ URL │ │────────────────────────│────────────────────────│ │ zack-test-org │ terraform-aws-asg │ │ zack-test-org │ terraform-aws-vpc │ │ zack-test-org │ terraform-aws-security │ │ zack-test-org │ terraform-aws-eks │ │ zack-test-org │ circleci-test-1 │ │────────────────────────│────────────────────────│ ALL REPOS THAT WERE TARGETED FOR PROCESSING AFTER FILTERING MISSING / MALFORMED REPOS │───────────────────│────────────────────────────────────────────────────│ │ REPO NAME │ REPO URL │ │───────────────────│────────────────────────────────────────────────────│ │ terraform-aws-vpc │ │ │ terraform-aws-eks │ │ │ circleci-test-1 │ │ │───────────────────│────────────────────────────────────────────────────│ REPOS THAT WERE SUCCESSFULLY CLONED TO THE LOCAL FILESYSTEM │───────────────────│────────────────────────────────────────────────────│ │ REPO NAME │ REPO URL │ │───────────────────│────────────────────────────────────────────────────│ │ terraform-aws-eks │ │ │ circleci-test-1 │ │ │ terraform-aws-vpc │ │ │───────────────────│────────────────────────────────────────────────────│ REPOS THAT SHOWED FILE CHANGES TO THEIR WORKING DIRECTORY FOLLOWING COMMAND EXECUTION │───────────────────│────────────────────────────────────────────────────│ │ REPO NAME │ REPO URL │ │───────────────────│────────────────────────────────────────────────────│ │ terraform-aws-eks │ │ │ terraform-aws-vpc │ │ │ circleci-test-1 │ │ │───────────────────│────────────────────────────────────────────────────│ REPOS THAT WERE SUPPLIED BY USER BUT DON\\'T EXIST (404\\'D) VIA GITHUB API │────────────────────────│──────────│ │ REPO NAME │ REPO URL │ │────────────────────────│──────────│ │ terraform-aws-asg │ │ │ terraform-aws-security │ │ │────────────────────────│──────────│ REPOS WHOSE SPECIFIED BRANCHES DID NOT EXIST ON THE REMOTE, AND SO WERE FIRST CREATED LOCALLY │───────────────────│────────────────────────────────────────────────────│ │ REPO NAME │ REPO URL │ │───────────────────│────────────────────────────────────────────────────│ │ terraform-aws-eks │ │ │ terraform-aws-vpc │ │ │ circleci-test-1 │ │ │───────────────────│────────────────────────────────────────────────────│ PULL REQUESTS OPENED │───────────────────│────────────────────────────────────────────────────────────│ │ REPO NAME │ PR URL │ │───────────────────│────────────────────────────────────────────────────────────│ │ circleci-test-1 │ │ │ terraform-aws-eks │ │ │ terraform-aws-vpc │ │ │───────────────────│────────────────────────────────────────────────────────────│ Getting startedInstallation option 1: HomebrewIf you are user, you can install by running$ brew install git-xargs Installation option 2: Installing published binariesInstallation option 3: Run go install or go getTry it out!ReferenceHow to supply commands or scripts to runThe API for is:git-xargs [-flags] Where is either the full path to a (Bash, Python, Ruby, etc) script on your local system or a binary. Note that, because the tool supports Bash scripts, Ruby scripts, Python scripts, etc, you must include the full filename for any given script, including its file extension.In other words, all the following usages are valid:git-xargs --repo gruntwork-io/cloud-nuke \\\\ --repo gruntwork-io/terraform-aws-eks \\\\ --branch-name my-branch \\\\ /usr/local/bin/my-bash-script.sh git-xargs --repos ./my-repos.txt \\\\ --branch-name my-other-branch \\\\ touch file1.txt file2.txt git-xargs --github-org my-github-org \\\\ --branch-name my-new-branch \\\\ \"$(pwd)/scripts/my-ruby-script.rb\" Debugging runtime errorsBy default, will conceal runtime errors as they occur because its log level setting is if not overridden by the flag.To see all errors your script or command may be generating, be sure to pass when running your command, like so:git-xargs --loglevel DEBUG \\\\ --repo zack-test-org/terraform-aws-eks \\\\ --branch-name master \\\\ --commit-message \"add blank file\" \\\\ --skip-pull-requests touch foo.txt When the log level is set to you should see new error output similar to the following:Total 195 (delta 159), reused 27 (delta 11), pack-reused 17 Repo=terraform-aws-eks [git-xargs] DEBU[2021-06-29T12:11:31-04:00] Created branch Branc h Name=refs/heads/master Repo=terraform-aws-eks [git-xargs] DEBU[2021-06-29T12:11:31-04:00] Error creating new branch Error =\"a branch named \\\\\"refs/heads/master\\\\\" already exists\" Repo=terraform-aws-eks [git-xargs] DEBU[2021-06-29T12:11:31-04:00] Error encountered while processing repo Error =\"a branch named \\\\\"refs/heads/master\\\\\" already exists\" Repo name=terraform-aws-eks Rate Limitinggit-xargs attempts to be a good citizen as regards consumption of the GitHub API. git-xargs conforms to GitHub\\'s API .In addition, git-xargs includes several features and flags to help you: Distinct processing channels for expensive and non-expensive workgit-xargs distinguishes between work that is safe to perform in parallel, such as certain git operations, and work that must be done with consideration of resource constraints, such as issuing open pull requests to GitHub\\'s API. Therefore, git-xargs is able to perform all concurrency-safe work as quickly as possible by leveraging goroutines, while treating the more expensive open pull request API calls separately. Pull requests are handled on a separate channel so that they can be buffered and retried in accordance with rate limiting feedback git-xargs is receiving from GitHub\\'s API. This means that git-xargs performs all the work upfront that it can as quickly as possible, and then moves on to serially process the pull request jobs that have resulted from the concurrency-safe work of cloning repositories, making file changes, checking the git worktree, etc.Automatic pull request retries when rate limitedBy default, git-xargs will re-attempt opening a pull request that failed due to rate limiting. The flag allows you to specify how many times you\\'d like a given pull request to be re-attempted in case of failure due to rate limiting. By default, the value is , meaning that if you do not pass this flag, will retry all rate-limit-blocked pull requests 3 times.Automatic backoff when rate limiting is detectedWhen git-xargs detects that it has been rate limited by GitHub, it begins requeuing failed pull requests for retry, but with an additional, larger buffer of time in between the next attempt. This larger buffer of time is intended to allow GitHub rate limit status to return to baseline for the git-xargs client. The flag specifies the number of seconds to wait when git-xargs detects it has been rate limited. Note that this extra buffer of time is in addition to the value specified by the flag.When they are provided by GitHub, git-xargs will instead use the values of any header, or the delta of seconds between the current time and the rate limit error\\'s reset time. When these two values are not available, git-xargs falls back to the user-specified value of , if the flag was passed, or the default value, which is 60 seconds.Specifying the pause between pull requestsThe GitHub\\'s API specify that clients should pause at least 1 second in between consecutive requests against expensive endpoints, such as the one for opening a new pull request. As a result, git-xargs defaults to pausing 1 second in between each pull request that is opened. The flag allows you to modify this value. For example, if you were to pass , then git-xargs will sleep for half a minute between issuing pull request API calls to GitHub.Guidelines and observations from testingIn local testing, the actual thresholds for when GitHub\\'s secondary rate limits kick in can vary depending on the number of repos you\\'re targeting and how long your script or command takes to complete. Secondary rate limits have been observed on jobs targeting as few as 10 repositories. If you are using the rate limiting flags with reasonable values, your job should never be rate-limited in the first place. If your job is consistently being rate-limited, try incrementally increasing the value you pass with the flag. Passing a higher value will increase the overall time your job takes to complete, but it will also greatly decrease the likelihood of your job tripping GitHub\\'s rate limits at all. Passing a lower value, or not passing the flag at all, will greatly increase the likelihood that your job is rate limited by GitHub. Branch behaviorPassing the () flag is required when running . If you specify the name of a branch that exists on your remote, its latest changes will be pulled locally prior to your command or script being run. If you specify the name of a new branch that does not yet exist on your remote, it will be created locally and pushed once your changes are committed.Default repository branchAny pull requests opened will be opened against the repository\\'s default branch (whether that\\'s , or or something else). You can supply an additional flag to change the target for your pull requests. Be aware that this will override the base branch name for ALL targeted repositories.Git file staging behaviorCurrently, will find and add any and all new files, as well as any existing files that were modified, within your repo and stage them prior to committing. If your script or command creates a new file, it will be committed. If your script or command edits an existing file, that change will also be committed.Paths and script locationsScripts may be placed anywhere on your system, but you are responsible for providing absolute paths to your scripts when invoking :git-xargs \\\\ --branch-name upgrade-tf-14 \\\\ --commit-message \"Update modules to Terraform 0.14\" \\\\ --repos data/batch3.txt \\\\ $(pwd)/scripts/my-ruby-script.rb orgit-xargs \\\\ --branch-name upgrade-tf-14 \\\\ --commit-message \"Update modules to Terraform 0.14\" \\\\ --repos data/batch3.txt \\\\ /usr/local/bin/my-ruby-script.rb If you need to compose more complex behavior into a single pull request, write a wrapper script that executes all your commands, or place all your logic into one script.How to target repos to run your scripts against supports four methods of targeting repos to run your selected scripts against. They are processed inthe order listed below, with whichever option is found first being used, and all others after it being ignored.Option  1: GitHub organization lookupIf you want the tool to find and select every repo in your GitHub organization, you can pass the name of your organization via the flag:git-xargs \\\\ --commit-message \"Update copyright year\" \\\\ --github-org \\\\ \"$(pwd)/scripts/update-copyright-year.sh\" This will signal the tool to look up, and page through, every repository in your GitHub organization and execute the scripts you passed.Option  2: Flat file of repository namesOftentimes, you want finer-grained control over the exact repos you are going to run your script against. In this case, you can use the flag and supply the path to a file defining the exact repos you want the tool to run your selected scripts against, like so:git-xargs \\\\ --commit-message \"Update copyright year\" \\\\ --repos data/batch2.txt \\\\ \"$(pwd)/scripts/update-copyright-year.sh\" In this example, batch2.txt looks like this:gruntwork-io/infrastructure-as-code-training gruntwork-io/infrastructure-live-acme gruntwork-io/infrastructure-live-multi-account-acme gruntwork-io/infrastructure-modules-acme gruntwork-io/infrastructure-modules-multi-account-acme Flat files contain one repo per line, each repository in the format of . Commas, trailing or preceding spaces, and quotes are all filtered out at runtime. This is done in case you end up copying your repo list from a JSON list or CSV file.Option  3: Pass in repos via command line argsAnother way to get fine-grained control is to pass in the individual repos you want to use via one or more arguments:git-xargs \\\\ --commit-message \"Update copyright year\" \\\\ --repo gruntwork-io/terragrunt \\\\ --repo gruntwork-io/terratest \\\\ --repo gruntwork-io/cloud-nuke \\\\ \"$(pwd)/scripts/update-copyright-year.sh\" Option  4: Pass in repos via stdinAnd one more (Unix-philosophy friendly) way to get fine-grained control is to pass in the individual repos you want touse by piping them in via , separating repo names with whitespace or newlines:echo \"gruntwork-io/terragrunt gruntwork-io/terratest\" | git-xargs \\\\ --commit-message \"Update copyright year\" \\\\ \"$(pwd)/scripts/update-copyright-year.sh\" Notable flags exposes several flags that allow you to customize its behavior to better suit your needs. For the latest info on flags, you should run . However, a couple of the flags are worth explaining more in depth here:| Flag | Description | Type | Required || ------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------- | -------- || | You must specify the name of the branch to make your local and remote changes on. You can further control branching behavior via as explained below. | String | Yes || | Specify the log level of messages git-xargs should print to STDOUT at runtime. By default, this is INFO - so only INFO level messages will be visible. Pass DEBUG to see runtime errors encountered by your scripts or commands. Accepted levels are TRACE, DEBUG, INFO, WARNING, ERROR, FATAL and PANIC. Default: . | String | No || | If you want to specify many repos and manage them in files (which makes batching and testing easier) then use this flag to pass the filepath to a repos file. See for more information. | String | No || | Use this flag to specify a single repo, e.g., . Can be passed multiple times to target several repos. | String | No || | If you want to target every repo in a Github org that your GITHUB_OAUTH_TOKEN has access to, pass the name of the Organization with this flag, to page through every repo via the Github API and target it. | String | No || | The commit message to use when creating commits. If you supply this flag, but neither the optional or flags, then the commit message value will be used for all three. Default: . Note that, by default, git-xargs will prepend [skip ci] to commit messages unless you pass the flag. If you wish to use an alternative prefix other than [skip ci], you can add the literal string to your --commit-message value. | String | No || | If you don\\'t want any pull requests opened, but would rather have your changes committed directly to your specified branch, pass this flag. Note that it won\\'t work if your Github repo is configured with branch protections on the branch you\\'re trying to commit directly to! Default: . | Boolean | No || | If you want to exclude archived (read-only) repositories from the list of targeted repos, pass this flag. Default: . | Boolean | No || | If you are in the process of testing out or your initial set of targeted repos, but you don\\'t want to make any changes via the Github API (pushing your local changes or opening pull requests) you can pass the dry-run flag. This is useful because the output report will still tell you which repos would have been affected, without actually making changes via the Github API to your remote repositories. Default: . | Boolean | No || | Whether to open pull requests in draft mode. Draft pull requests are available for public GitHub repositories and private repositories in GitHub tiered accounts. See for more details. Default: false. | Boolean | No || | The number of seconds to wait between opening serial pull requests. If you are being rate limited, continue to increase this value until rate limiting eases. Note, this value cannot be negative, so if you pass a value less than 1, the seconds to wait between pull requests will be set to 1 second. Default: second. | Integer | No || | The number of times to retry a pull request that failed due to rate limiting. Default: . | Integer | No || | The number of seconds to pause once git-xargs has detected it has been rate limited. Note that this buffer is in addition to the value of --seconds-between-prs. If you are regularly being rate limited, increase this value until rate limiting eases. Default: seconds. | Integer | No || | By default, git-xargs will prepend [skip ci] to its commit messages to prevent large git-xargs jobs from creating expensive CI jobs excessively. If you pass the flag, then git-xargs will not prepend [skip ci]. Default: false, meaning that [skip ci] will be prepended to commit messages. | Bool | No || | An optional slice of GitHub usernames, separated by commas, to request reviews from after a pull request is successfully opened. Default: empty slice, meaning that no reviewers will be requested. | String | No || | An optional slice of GitHub team names, separated by commas, to request reviews from after a pull request is successfully opened. Default: empty slice, meaning that no team reviewers will be requested. IMPORTANT: Please read and understand on this functionality before using it! Only certain GitHub organizations / payment plans support this functionality. | String | No | Best practices, tips and tricksWrite your script to run against a single repoWrite your script as if it\\'s operating on a single repo, then target many repos with . Remember that at runtime, each of the scripts you select will be run, in the order you specify, once per repo that you\\'ve targeted.Handling prerequisites and third party binariesIt is currently assumed that bash script authors will be responsible for checking for prerequisites within their own scripts. If you are adding a new bash script to accomplish some new task across repos, consider using the to ensure the operator has any required binaries installed.Grouping your repos into separate batchesThis is a pattern that ended up working out well for us as we wrote and executed more and more ambitious scripts across our many repos as a team:By breaking your target repos into separate batches, (batch1.txt, batch2.txt, batch3.txt) and starting with a few repos (or even one repo!) in the initial batches, and then gradually expanding the batches in size, you can easily test your new scripts against a few repos and double check the generated pull requests for any issues prior to widening your target batches.How git-xargs worksThis section provides a more in-depth look at how the tool works under the hood.Tasks this tool is well-suited forThe following is a non-exhaustive list of potential use cases for :If you can instrument the logic in a script, you can use ContributingContributing scripts to this projectWe hope that this tool will help save you some time as you apply it to your own automations and maintenance tasks. We also welcome the community to contribute back scripts that everyone can use and benefit from.Initially, we\\'ll add these scripts to the directory in this repository and will eventually organize them into sub-folders depending on their purposes / use cases. If you would like to have your script considered for inclusion in this repo, please first ensure that it is:Once you\\'ve done this, please feel free to open a pull request adding your script to the directory for consideration.Thanks for contributing back! Our hope is that eventually this repo will contain many useful generic scripts for common maintenance and upgrading tasks that everyone can leverage to save time.Building the binary from sourceClone this repository and then run the following command from the root of the repository:go build The binary will be present in the repository root.Running the tool without building the binaryAlternatively, you can run the tool directly without building the binary, like so:./go run main.go \\\\ --branch-name test-branch \\\\ --commit-message \"Add MIT License\" \\\\ --repos data/test-repos.txt \\\\ $(pwd)/scripts/add-license.sh This is especially helpful if you are developing against the tool and want to quickly verify your changes.Running testsTests are included within their respective packages.go test -v ./... LicenseThis code is released under the Apache 2.0 License. See\\n\\n        ### Summary:\\n        git-xargs is a command-line tool (CLI) for making updates across multiple Github repositories with a single command. .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_dataset[0]['prompt_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=4,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"llama2-7b-readsum-29-06-2024\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    "    # push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5831/5831 [00:02<00:00, 2531.61 examples/s]\n",
      "Map: 100%|██████████| 834/834 [00:00<00:00, 2742.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"prompt_text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbunbohue1906\u001b[0m (\u001b[33mlocseo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/4TData/vuquang/Improved-README-Summarization/summarization/wandb/run-20240629_221553-xhv5opfq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/locseo/huggingface/runs/xhv5opfq' target=\"_blank\">llama2-7b-readsum-29-06-2024</a></strong> to <a href='https://wandb.ai/locseo/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/locseo/huggingface' target=\"_blank\">https://wandb.ai/locseo/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/locseo/huggingface/runs/xhv5opfq' target=\"_blank\">https://wandb.ai/locseo/huggingface/runs/xhv5opfq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11660' max='11660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11660/11660 4:13:03, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.496900</td>\n",
       "      <td>1.527825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.926300</td>\n",
       "      <td>1.394772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.761400</td>\n",
       "      <td>1.438260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11660, training_loss=1.1336701515812817, metrics={'train_runtime': 15190.0471, 'train_samples_per_second': 1.535, 'train_steps_per_second': 0.768, 'total_flos': 6.443850879239455e+17, 'train_loss': 1.1336701515812817, 'epoch': 3.9993140113188135})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readsum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
